# Exploring the Problem of Exploding and Vanishing Gradients in Deep Neural Netwroks
Increasing the depth of a neural netwroks generally leads to increased accuracy. With the increasing depth in neural netwroks, the gradients of the loss function with respect to the unknown parameters (weights and biases) may either explore or vanish.

This work is aimed to use MNIST dataset and MLPs to explore this problem.
