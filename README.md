# explore-gradients
Explore the problem of vanishing and exploding gradients
With the increasing depth in neural netwroks, the gradients of the loss function with respect to the unknown parameters (weights and biases) may either explore or vanish.

This work is aimed to use MNIST dataset and MLPs to explore this problem.
